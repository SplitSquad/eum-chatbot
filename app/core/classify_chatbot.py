## ğŸ“š 2. ì „ë¬¸ ì§ˆì˜ ë¶„ë¥˜ê¸° (RAG)

# app/core/classify_chatbot.py

from typing import Dict
import json
from loguru import logger
from app.core.llm_client import get_llm_client

DOMAIN_PROMPT_TEMPLATE = """
You're a query classifier. Classify the query into whether it needs a specialized RAG (Retrieval-Augmented Generation),
identify which domain it belongs to, and whether it's a general, reasoning, or search-type query.

Return in this **exact** JSON format:

```json
{{
  "needs_rag": true/false,
  "rag_domain": "none" or "visa" or "finance" or "medical" or "employment" or "housing" or "culture",
  "query_type": "general" or "reasoning" or "search"
}}

Query: "{query}" """

AGENTIC_PROMPT_TEMPLATE = """
You're a query classifier. Determine if the query requires agentic capabilities (the ability to take actions or make decisions).

Return in this **exact** JSON format:

```json
{{
  "is_agentic": true/false,
  "agentic_type": "none" or "action" or "decision" or "planning"
}}

Query: "{query}" """

SPECIALIZED_PROMPT_TEMPLATE = """
You're a query classifier. Determine if the query requires specialized knowledge or expertise.

Return in this **exact** JSON format:

```json
{{
  "is_specialized": true/false,
  "specialization_type": "none" or "technical" or "professional" or "academic"
}}

Query: "{query}" """

async def classify_domain_query(query: str) -> Dict[str, str]:
    """
    ì£¼ì–´ì§„ ì¿¼ë¦¬ë¥¼ ë¶„ë¥˜í•˜ì—¬ RAGê°€ í•„ìš”í•œì§€, ì–´ë–¤ ë„ë©”ì¸ì— ì†í•˜ëŠ”ì§€, ê·¸ë¦¬ê³  ì¿¼ë¦¬ íƒ€ì…ì„ ê²°ì •í•©ë‹ˆë‹¤.

    Args:
        query (str): ë¶„ë¥˜í•  ì¿¼ë¦¬ë¬¸ì¥

    Returns:
        Dict[str, str]: ë¶„ë¥˜ ê²°ê³¼ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        llm_client = get_llm_client()
        
        # ë„ë©”ì¸ ë¶„ë¥˜ ìš”ì²­
        result = await llm_client.generate(
            prompt=DOMAIN_PROMPT_TEMPLATE.format(query=query)
        )
        
        # JSON ì¶”ì¶œ ë° ì²˜ë¦¬
        json_str = result.strip().strip("```json").strip("```").strip()
        logger.debug(f"[ë„ë©”ì¸ ë¶„ë¥˜ê¸°] ì‘ë‹µ: {json_str}")
        
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        logger.error(f"[ë„ë©”ì¸ ë¶„ë¥˜ê¸°] JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        logger.error(f"[ë„ë©”ì¸ ë¶„ë¥˜ê¸°] ì›ë³¸ ì‘ë‹µ: {result}")
        raise ValueError(f"[ë„ë©”ì¸ ë¶„ë¥˜ê¸°] íŒŒì‹± ì˜¤ë¥˜: {e}\nì›ë³¸ ì‘ë‹µ: {result}")
    except Exception as e:
        logger.error(f"[ë„ë©”ì¸ ë¶„ë¥˜ê¸°] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise ValueError(f"[ë„ë©”ì¸ ë¶„ë¥˜ê¸°] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

async def classify_agentic_query(query: str) -> Dict[str, str]:
    """
    ì£¼ì–´ì§„ ì¿¼ë¦¬ê°€ ì—ì´ì „íŠ¸ ëŠ¥ë ¥ì´ í•„ìš”í•œì§€ ë¶„ë¥˜í•©ë‹ˆë‹¤.

    Args:
        query (str): ë¶„ë¥˜í•  ì¿¼ë¦¬ë¬¸ì¥

    Returns:
        Dict[str, str]: ë¶„ë¥˜ ê²°ê³¼ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        llm_client = get_llm_client()
        
        # ì—ì´ì „íŠ¸ ë¶„ë¥˜ ìš”ì²­
        result = await llm_client.generate(
            prompt=AGENTIC_PROMPT_TEMPLATE.format(query=query)
        )
        
        # JSON ì¶”ì¶œ ë° ì²˜ë¦¬
        json_str = result.strip().strip("```json").strip("```").strip()
        logger.debug(f"[ì—ì´ì „íŠ¸ ë¶„ë¥˜ê¸°] ì‘ë‹µ: {json_str}")
        
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        logger.error(f"[ì—ì´ì „íŠ¸ ë¶„ë¥˜ê¸°] JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        logger.error(f"[ì—ì´ì „íŠ¸ ë¶„ë¥˜ê¸°] ì›ë³¸ ì‘ë‹µ: {result}")
        raise ValueError(f"[ì—ì´ì „íŠ¸ ë¶„ë¥˜ê¸°] íŒŒì‹± ì˜¤ë¥˜: {e}\nì›ë³¸ ì‘ë‹µ: {result}")
    except Exception as e:
        logger.error(f"[ì—ì´ì „íŠ¸ ë¶„ë¥˜ê¸°] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise ValueError(f"[ì—ì´ì „íŠ¸ ë¶„ë¥˜ê¸°] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

async def classify_specialized_query(query: str) -> Dict[str, str]:
    """
    ì£¼ì–´ì§„ ì¿¼ë¦¬ê°€ ì „ë¬¸ ì§€ì‹ì´ í•„ìš”í•œì§€ ë¶„ë¥˜í•©ë‹ˆë‹¤.

    Args:
        query (str): ë¶„ë¥˜í•  ì¿¼ë¦¬ë¬¸ì¥

    Returns:
        Dict[str, str]: ë¶„ë¥˜ ê²°ê³¼ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        llm_client = get_llm_client()
        
        # ì „ë¬¸ ë¶„ë¥˜ ìš”ì²­
        result = await llm_client.generate(
            prompt=SPECIALIZED_PROMPT_TEMPLATE.format(query=query)
        )
        
        # JSON ì¶”ì¶œ ë° ì²˜ë¦¬
        json_str = result.strip().strip("```json").strip("```").strip()
        logger.debug(f"[ì „ë¬¸ ë¶„ë¥˜ê¸°] ì‘ë‹µ: {json_str}")
        
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        logger.error(f"[ì „ë¬¸ ë¶„ë¥˜ê¸°] JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        logger.error(f"[ì „ë¬¸ ë¶„ë¥˜ê¸°] ì›ë³¸ ì‘ë‹µ: {result}")
        raise ValueError(f"[ì „ë¬¸ ë¶„ë¥˜ê¸°] íŒŒì‹± ì˜¤ë¥˜: {e}\nì›ë³¸ ì‘ë‹µ: {result}")
    except Exception as e:
        logger.error(f"[ì „ë¬¸ ë¶„ë¥˜ê¸°] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise ValueError(f"[ì „ë¬¸ ë¶„ë¥˜ê¸°] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
